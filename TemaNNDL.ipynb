{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Target variable: Price"
      ],
      "metadata": {
        "id": "rZVBlCL97-kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install the packages from the requirement.txt file:\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uBNyyWvE-rqz",
        "outputId": "6b055a77-931c-4fa9-fa44-403ef323bad6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting beautifulsoup4==4.12.0 (from -r requirements.txt (line 1))\n",
            "  Downloading beautifulsoup4-4.12.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.2/132.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting emoji==2.2.0 (from -r requirements.txt (line 2))\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gensim==4.3.1 (from -r requirements.txt (line 3))\n",
            "  Downloading gensim-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython==8.11.0 (from -r requirements.txt (line 4))\n",
            "  Downloading ipython-8.11.0-py3-none-any.whl (793 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.3/793.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras==2.12.0 (from -r requirements.txt (line 5))\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib==3.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.8.1)\n",
            "Collecting numpy==1.23.5 (from -r requirements.txt (line 8))\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.5.3 (from -r requirements.txt (line 9))\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==4.21.12 (from -r requirements.txt (line 10))\n",
            "  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pysentiment2==0.1.1 (from -r requirements.txt (line 11))\n",
            "  Downloading pysentiment2-0.1.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==1.0.2 (from -r requirements.txt (line 12))\n",
            "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.10.1 (from -r requirements.txt (line 13))\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scorecardpy==0.1.9.2 (from -r requirements.txt (line 14))\n",
            "  Downloading scorecardpy-0.1.9.2.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting seaborn==0.12.2 (from -r requirements.txt (line 15))\n",
            "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting statsmodels==0.13.5 (from -r requirements.txt (line 16))\n",
            "  Downloading statsmodels-0.13.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.12.0 (from -r requirements.txt (line 17))\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.0.0 (from -r requirements.txt (line 18))\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m650.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.65.0 (from -r requirements.txt (line 19))\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.27.4 (from -r requirements.txt (line 20))\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost==1.7.4 (from -r requirements.txt (line 21))\n",
            "  Downloading xgboost-1.7.4-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.12.0->-r requirements.txt (line 1)) (2.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.3.1->-r requirements.txt (line 3)) (6.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython==8.11.0->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython==8.11.0->-r requirements.txt (line 4)) (4.4.2)\n",
            "Collecting jedi>=0.16 (from ipython==8.11.0->-r requirements.txt (line 4))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython==8.11.0->-r requirements.txt (line 4)) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython==8.11.0->-r requirements.txt (line 4)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython==8.11.0->-r requirements.txt (line 4)) (3.0.43)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython==8.11.0->-r requirements.txt (line 4)) (2.16.1)\n",
            "Collecting stack-data (from ipython==8.11.0->-r requirements.txt (line 4))\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.10/dist-packages (from ipython==8.11.0->-r requirements.txt (line 4)) (5.7.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython==8.11.0->-r requirements.txt (line 4)) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 6)) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 6)) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 6)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r requirements.txt (line 7)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r requirements.txt (line 7)) (2023.12.25)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->-r requirements.txt (line 9)) (2023.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.0.2->-r requirements.txt (line 12)) (3.4.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels==0.13.5->-r requirements.txt (line 16)) (0.5.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0->-r requirements.txt (line 17))\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (1.62.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (0.4.23)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0->-r requirements.txt (line 17))\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0->-r requirements.txt (line 17))\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->-r requirements.txt (line 17)) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 18)) (3.13.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 18)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 18)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 18)) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 18))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 18))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->-r requirements.txt (line 18))\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->-r requirements.txt (line 18))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->-r requirements.txt (line 18))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->-r requirements.txt (line 18))\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->-r requirements.txt (line 18))\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->-r requirements.txt (line 18))\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->-r requirements.txt (line 18))\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->-r requirements.txt (line 18))\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->-r requirements.txt (line 18))\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.0->-r requirements.txt (line 18))\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4->-r requirements.txt (line 20)) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4->-r requirements.txt (line 20)) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4->-r requirements.txt (line 20)) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.27.4->-r requirements.txt (line 20))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 18)) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 18)) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 18))\n",
            "  Downloading lit-18.1.2.tar.gz (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.0/161.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.4->-r requirements.txt (line 20)) (2023.6.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0->-r requirements.txt (line 17)) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython==8.11.0->-r requirements.txt (line 4)) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython==8.11.0->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython==8.11.0->-r requirements.txt (line 4)) (0.2.13)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0->-r requirements.txt (line 17)) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0->-r requirements.txt (line 17))\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0->-r requirements.txt (line 17)) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0->-r requirements.txt (line 17)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0->-r requirements.txt (line 17)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.4->-r requirements.txt (line 20)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.4->-r requirements.txt (line 20)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.4->-r requirements.txt (line 20)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.4->-r requirements.txt (line 20)) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->-r requirements.txt (line 18)) (2.1.5)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython==8.11.0->-r requirements.txt (line 4))\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython==8.11.0->-r requirements.txt (line 4))\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting pure-eval (from stack-data->ipython==8.11.0->-r requirements.txt (line 4))\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->-r requirements.txt (line 18)) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0->-r requirements.txt (line 17)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0->-r requirements.txt (line 17)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0->-r requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0->-r requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0->-r requirements.txt (line 17)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0->-r requirements.txt (line 17)) (3.2.2)\n",
            "Building wheels for collected packages: emoji, scorecardpy, lit\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234912 sha256=5fc62a0876e03d3a08849ecf41cc7f7c8dee693cb20365e99a77ac3771a84954\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/3d/88/51a592b9ad17e7899126563698b4e3961983ebe85747228ba6\n",
            "  Building wheel for scorecardpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scorecardpy: filename=scorecardpy-0.1.9.2-py3-none-any.whl size=57818 sha256=4ab56cf9c8dd87f6ce4317738f7921c58e05c5d7b6dc4dfe7d5bd02665a4f64d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/cc/f9/576483520f8f4c3832fdcc1d94297be8176b74d1147c3a8b08\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-18.1.2-py3-none-any.whl size=96368 sha256=969a4cf1556bbc174ceb56f979acbb4e7a67b4b1c7fbb53311fb5529d05b0788\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/4d/9c/3e28d23c2c6fc6a9bd89c91a7b7ff775fc71a41ac9a52563e9\n",
            "Successfully built emoji scorecardpy lit\n",
            "Installing collected packages: tokenizers, pure-eval, lit, tqdm, tensorflow-estimator, protobuf, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, keras, jedi, gast, executing, emoji, beautifulsoup4, asttokens, stack-data, scipy, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, xgboost, transformers, statsmodels, scikit_learn, pysentiment2, ipython, google-auth-oauthlib, gensim, tensorboard, seaborn, scorecardpy, tensorflow, triton, torch\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.2\n",
            "    Uninstalling tqdm-4.66.2:\n",
            "      Successfully uninstalled tqdm-4.66.2\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.12.3\n",
            "    Uninstalling beautifulsoup4-4.12.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.12.3\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.0.3\n",
            "    Uninstalling xgboost-2.0.3:\n",
            "      Successfully uninstalled xgboost-2.0.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.14.1\n",
            "    Uninstalling statsmodels-0.14.1:\n",
            "      Successfully uninstalled statsmodels-0.14.1\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.2\n",
            "    Uninstalling gensim-4.3.2:\n",
            "      Successfully uninstalled gensim-4.3.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.13.1\n",
            "    Uninstalling seaborn-0.13.1:\n",
            "      Successfully uninstalled seaborn-0.13.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.0.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.11.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "plotnine 0.12.4 requires statsmodels>=0.14.0, but you have statsmodels 0.13.5 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.21.12 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.12.0 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asttokens-2.4.1 beautifulsoup4-4.12.0 emoji-2.2.0 executing-2.0.1 gast-0.4.0 gensim-4.3.1 google-auth-oauthlib-1.0.0 ipython-8.11.0 jedi-0.19.1 keras-2.12.0 lit-18.1.2 numpy-1.23.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pandas-1.5.3 protobuf-4.21.12 pure-eval-0.2.2 pysentiment2-0.1.1 scikit_learn-1.0.2 scipy-1.10.1 scorecardpy-0.1.9.2 seaborn-0.12.2 stack-data-0.6.3 statsmodels-0.13.5 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tokenizers-0.13.3 torch-2.0.0 tqdm-4.65.0 transformers-4.27.4 triton-2.0.0 xgboost-1.7.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "numpy",
                  "pandas",
                  "sklearn"
                ]
              },
              "id": "280b84711e97425691de6a06a673e54d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sqYRMOen6ahz"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.inspection import plot_partial_dependence\n",
        "\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data\n",
        "path='cleaned_all_phones.csv'\n",
        "phone_info = pd.read_csv(path,\n",
        "                       index_col=False,\n",
        "                       sep=',', encoding='utf-8')"
      ],
      "metadata": {
        "id": "0PSpHMj78Tr9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## get to know the data\n",
        "print('Shape of data: ',phone_info.shape,'\\n')\n",
        "print('Head of data: \\n',phone_info.head(10),'\\n')\n",
        "print('Descriptive statistics of data: \\n')\n",
        "print('Numerical columns: \\n',phone_info.describe(include=np.number),'\\n')\n",
        "print('Categorical columns: \\n',phone_info.describe(include=object),'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XqKWGUG-_Bi",
        "outputId": "0b82bce3-4e81-4799-ea1a-0848ba0aec66"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data:  (1512, 22) \n",
            "\n",
            "Head of data: \n",
            "          phone_name   brand           os  inches resolution  battery  \\\n",
            "0      Y6II Compact  Huawei  Android 5.1     5.0   720x1280     2200   \n",
            "1          K20 plus      LG  Android 7.0     5.3   720x1280     2700   \n",
            "2    P8 Lite (2017)  Huawei  Android 7.0     5.2  1080x1920     3000   \n",
            "3      Redmi Note 4  Xiaomi  Android 6.0     5.5  1080x1920     4100   \n",
            "4               P10  Huawei  Android 7.0     5.1  1080x1920     3200   \n",
            "5        Xperia XA1    Sony  Android 7.0     5.0   720x1280     2300   \n",
            "6          P10 Lite  Huawei  Android 7.0     5.2  1080x1920     3000   \n",
            "7          P10 Plus  Huawei  Android 7.0     5.5  1440x2560     3750   \n",
            "8  Xperia XA1 Ultra    Sony  Android 7.0     6.0  1080x1920     2700   \n",
            "9          X power2      LG  Android 7.0     5.5   720x1280     4500   \n",
            "\n",
            "  battery_type  ram(GB) announcement_date  weight(g)  ...  video_1080p  \\\n",
            "0        Li-Po        2        2016-09-01      140.0  ...        False   \n",
            "1       Li-Ion        2        2016-12-01      140.0  ...         True   \n",
            "2       Li-Ion        4        2017-01-01      147.0  ...         True   \n",
            "3        Li-Po        4        2017-01-01      165.0  ...         True   \n",
            "4       Li-Ion        4        2017-02-01      145.0  ...         True   \n",
            "5       Li-Ion        3        2017-02-01      143.0  ...         True   \n",
            "6        Li-Po        4        2017-02-01      146.0  ...         True   \n",
            "7       Li-Ion        6        2017-02-01      165.0  ...         True   \n",
            "8       Li-Ion        4        2017-02-01      188.0  ...         True   \n",
            "9       Li-Ion        2        2017-02-01      164.0  ...         True   \n",
            "\n",
            "   video_4K  video_8K  video_30fps  video_60fps  video_120fps  video_240fps  \\\n",
            "0     False     False         True        False         False         False   \n",
            "1     False     False         True        False         False         False   \n",
            "2     False     False         True        False         False         False   \n",
            "3     False     False         True        False          True         False   \n",
            "4      True     False         True         True         False         False   \n",
            "5     False     False         True        False         False         False   \n",
            "6     False     False         True        False         False         False   \n",
            "7      True     False         True         True         False         False   \n",
            "8     False     False         True        False         False         False   \n",
            "9     False     False         True        False         False         False   \n",
            "\n",
            "   video_480fps  video_960fps  price(USD)  \n",
            "0         False         False       120.0  \n",
            "1         False         False       100.0  \n",
            "2         False         False       420.0  \n",
            "3         False         False       150.0  \n",
            "4         False         False       420.0  \n",
            "5         False         False       140.0  \n",
            "6         False         False       420.0  \n",
            "7         False         False       170.0  \n",
            "8         False         False       250.0  \n",
            "9         False         False       170.0  \n",
            "\n",
            "[10 rows x 22 columns] \n",
            "\n",
            "Descriptive statistics of data: \n",
            "\n",
            "Numerical columns: \n",
            "             inches      battery      ram(GB)    weight(g)  storage(GB)  \\\n",
            "count  1512.000000  1512.000000  1512.000000  1512.000000  1512.000000   \n",
            "mean      6.422460  4389.798942     6.683862   187.636243   109.164683   \n",
            "std       0.477043   784.607022     2.701433    26.200115    74.436484   \n",
            "min       3.800000  1821.000000     1.000000   130.000000     1.000000   \n",
            "25%       6.300000  4000.000000     4.000000   175.000000    64.000000   \n",
            "50%       6.500000  4500.000000     8.000000   187.000000   128.000000   \n",
            "75%       6.670000  5000.000000     8.000000   197.250000   128.000000   \n",
            "max      10.400000  7250.000000    24.000000   500.000000   512.000000   \n",
            "\n",
            "        price(USD)  \n",
            "count  1512.000000  \n",
            "mean    337.847036  \n",
            "std     266.740821  \n",
            "min      40.000000  \n",
            "25%     179.997500  \n",
            "50%     260.000000  \n",
            "75%     400.000000  \n",
            "max    2300.000000   \n",
            "\n",
            "Categorical columns: \n",
            "        phone_name   brand          os resolution battery_type  \\\n",
            "count        1512    1512        1512       1512         1512   \n",
            "unique       1496      13          34         85            2   \n",
            "top           V30  Xiaomi  Android 11  1080x2400        Li-Po   \n",
            "freq            3     264         322        437         1242   \n",
            "\n",
            "       announcement_date  \n",
            "count               1512  \n",
            "unique               665  \n",
            "top           2018-05-01  \n",
            "freq                  20   \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the number of duplicated rows and remove any duplicates after that:\n",
        "print('Number of duplicated samples: ',phone_info[phone_info.duplicated()].shape[0])\n",
        "trav_ins=phone_info.drop_duplicates(keep='first')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozlrJY7J_AX2",
        "outputId": "44c5473c-83e5-4f6a-ab16-0297dc4db9e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicated samples:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Overview missing values per feature: \\n',phone_info.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DGCnnSlDjrB",
        "outputId": "f746595c-c038-4550-ad42-db3c7721ad7e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overview missing values per feature: \n",
            " phone_name           0\n",
            "brand                0\n",
            "os                   0\n",
            "inches               0\n",
            "resolution           0\n",
            "battery              0\n",
            "battery_type         0\n",
            "ram(GB)              0\n",
            "announcement_date    0\n",
            "weight(g)            0\n",
            "storage(GB)          0\n",
            "video_720p           0\n",
            "video_1080p          0\n",
            "video_4K             0\n",
            "video_8K             0\n",
            "video_30fps          0\n",
            "video_60fps          0\n",
            "video_120fps         0\n",
            "video_240fps         0\n",
            "video_480fps         0\n",
            "video_960fps         0\n",
            "price(USD)           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phone_info['video_720p']=phone_info['video_720p'].map({'FALSE':0,'TRUE':1})\n",
        "phone_info['video_1080p']=phone_info['video_1080p'].map({'FALSE':0,'TRUE':1})\n",
        "phone_info['video_4K']=phone_info['video_4K'].map({'FALSE':0,'TRUE':1})\n",
        "phone_info['video_8K']=phone_info['video_8K'].map({'FALSE':0,'TRUE':1})\n",
        "phone_info['video_30fps']=phone_info['video_30fps'].map({'FALSE':0,'TRUE':1})\n",
        "phone_info['video_60fps']=phone_info['video_60fps'].map({'FALSE':0,'TRUE':1})\n",
        "phone_info['video_120fps']=phone_info['video_120fps'].map({'FALSE':0,'TRUE':1})\n",
        "phone_info['video_240fps']=phone_info['video_240fps'].map({'FALSE':0,'TRUE':1})\n",
        "phone_info['video_480fps']=phone_info['video_480fps'].map({'FALSE':0,'TRUE':1})\n",
        "phone_info['video_960fps']=phone_info['video_960fps'].map({'FALSE':0,'TRUE':1})"
      ],
      "metadata": {
        "id": "T8JfgMhjAFOi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def group_categorical_levels(grouping_criteria,data):\n",
        "    categorical_columns=data.select_dtypes(include=object).columns\n",
        "\n",
        "    for cat_col in categorical_columns:\n",
        "        category_counts=data[cat_col].value_counts()\n",
        "        print('Categorical column: ',cat_col)\n",
        "        print('Category counts before grouping: \\n',category_counts,'\\n')\n",
        "        data[cat_col]=np.where(data[cat_col].isin(category_counts[category_counts.lt(grouping_criteria)].index),'Other',data[cat_col])\n",
        "        if len(data[cat_col].value_counts().keys())!=len(category_counts.keys()):\n",
        "            print('Category counts after grouping: \\n',data[cat_col].value_counts(),'\\n\\n')\n",
        "    return data"
      ],
      "metadata": {
        "id": "BB7TDnOwB-fA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phone_info=group_categorical_levels(grouping_criteria=2000,\n",
        "                         data=phone_info.copy())\n",
        "phone_info=pd.get_dummies(data=trav_ins,\n",
        "                        prefix_sep='_',columns=phone_info.select_dtypes(include=object).columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmOq-ZLGCBHW",
        "outputId": "5a55e783-2263-40aa-b181-42facdf55dde"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical column:  phone_name\n",
            "Category counts before grouping: \n",
            " V30                         3\n",
            "K5                          2\n",
            "7 Pro                       2\n",
            "9                           2\n",
            "6                           2\n",
            "                           ..\n",
            "Galaxy A11                  1\n",
            "Redmi Note 9 Pro (India)    1\n",
            "Redmi Note 9 Pro Max        1\n",
            "Find X2                     1\n",
            "vivo iQOO Z7 Pro            1\n",
            "Name: phone_name, Length: 1496, dtype: int64 \n",
            "\n",
            "Category counts after grouping: \n",
            " Other    1512\n",
            "Name: phone_name, dtype: int64 \n",
            "\n",
            "\n",
            "Categorical column:  brand\n",
            "Category counts before grouping: \n",
            " Xiaomi     264\n",
            "Oppo       213\n",
            "Samsung    206\n",
            "Vivo       168\n",
            "Realme     157\n",
            "Huawei     137\n",
            "Honor      124\n",
            "LG          75\n",
            "OnePlus     47\n",
            "Lenovo      43\n",
            "Sony        37\n",
            "Apple       22\n",
            "Google      19\n",
            "Name: brand, dtype: int64 \n",
            "\n",
            "Category counts after grouping: \n",
            " Other    1512\n",
            "Name: brand, dtype: int64 \n",
            "\n",
            "\n",
            "Categorical column:  os\n",
            "Category counts before grouping: \n",
            " Android 11                322\n",
            "Android 10                317\n",
            "Android 12                233\n",
            "Android 9.0               210\n",
            "Android 13                154\n",
            "Android 8.1                83\n",
            "Android 8.0                55\n",
            "Android 7.0                33\n",
            "Android 7.1.1              17\n",
            "Android 7.1                14\n",
            "Android 7.1.2              13\n",
            "EMUI 12                     6\n",
            "Android 6.0                 6\n",
            "Android 8.1 Oreo            5\n",
            "iOS 16                      4\n",
            "iOS 15                      4\n",
            "iOS 14.1                    4\n",
            "iOS 13                      4\n",
            "iOS 12                      3\n",
            "Android 6                   3\n",
            "Android                     3\n",
            "Android 12 or 13            2\n",
            "Android 5.1                 2\n",
            "Android 9.0 Pie             2\n",
            "Android 8.0 Oreo            2\n",
            "Android 6.0.1               2\n",
            "EMUI 13                     2\n",
            "Android 10/ Android 11      1\n",
            "iOS 15.4                    1\n",
            "iOS 11.1.1                  1\n",
            "iOS 11                      1\n",
            "Android 12L                 1\n",
            "Tizen 3.0                   1\n",
            "Android 7.0.1               1\n",
            "Name: os, dtype: int64 \n",
            "\n",
            "Category counts after grouping: \n",
            " Other    1512\n",
            "Name: os, dtype: int64 \n",
            "\n",
            "\n",
            "Categorical column:  resolution\n",
            "Category counts before grouping: \n",
            " 1080x2400    437\n",
            "720x1600     175\n",
            "1080x2340    171\n",
            "1080x2408     69\n",
            "720x1520      47\n",
            "            ... \n",
            "1200x2000      1\n",
            "1224x2664      1\n",
            "720x1640       1\n",
            "1860x2480      1\n",
            "2156x2344      1\n",
            "Name: resolution, Length: 85, dtype: int64 \n",
            "\n",
            "Category counts after grouping: \n",
            " Other    1512\n",
            "Name: resolution, dtype: int64 \n",
            "\n",
            "\n",
            "Categorical column:  battery_type\n",
            "Category counts before grouping: \n",
            " Li-Po     1242\n",
            "Li-Ion     270\n",
            "Name: battery_type, dtype: int64 \n",
            "\n",
            "Category counts after grouping: \n",
            " Other    1512\n",
            "Name: battery_type, dtype: int64 \n",
            "\n",
            "\n",
            "Categorical column:  announcement_date\n",
            "Category counts before grouping: \n",
            " 2018-05-01    20\n",
            "2018-03-01    16\n",
            "2019-09-01    16\n",
            "2018-10-01    15\n",
            "2019-04-01    14\n",
            "              ..\n",
            "2021-02-04     1\n",
            "2021-02-02     1\n",
            "2021-01-27     1\n",
            "2021-01-25     1\n",
            "2023-08-31     1\n",
            "Name: announcement_date, Length: 665, dtype: int64 \n",
            "\n",
            "Category counts after grouping: \n",
            " Other    1512\n",
            "Name: announcement_date, dtype: int64 \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features (X) and target variable (y)\n",
        "X = phone_info.drop(columns=['price(USD)'])  # Features\n",
        "y = phone_info['price(USD)']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a linear regression model as benchmark\n",
        "linear_reg_model = LinearRegression()\n",
        "linear_reg_model.fit(X_train, y_train)\n",
        "linear_reg_predictions = linear_reg_model.predict(X_test)\n",
        "\n",
        "# Calculate metrics for linear regression model\n",
        "linear_reg_mae = mean_absolute_error(y_test, linear_reg_predictions)\n",
        "linear_reg_mse = mean_squared_error(y_test, linear_reg_predictions)\n",
        "linear_reg_rmse = np.sqrt(linear_reg_mse)\n",
        "\n",
        "print(\"Linear Regression Metrics:\")\n",
        "print(\"MAE:\", linear_reg_mae)\n",
        "print(\"MSE:\", linear_reg_mse)\n",
        "print(\"RMSE:\", linear_reg_rmse)\n",
        "\n",
        "# Train a neural network model\n",
        "nn_model = Sequential()\n",
        "# Define your neural network architecture, e.g.,:\n",
        "nn_model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "nn_model.add(Dense(32, activation='relu'))\n",
        "nn_model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "nn_model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "nn_model.fit(X_train_scaled, y_train, epochs=200, batch_size=32, verbose=1)\n",
        "\n",
        "# Predict using the trained neural network model\n",
        "nn_predictions = nn_model.predict(X_test_scaled).flatten()\n",
        "\n",
        "# Calculate metrics for neural network model\n",
        "nn_mae = mean_absolute_error(y_test, nn_predictions)\n",
        "nn_mse = mean_squared_error(y_test, nn_predictions)\n",
        "nn_rmse = np.sqrt(nn_mse)\n",
        "\n",
        "print(\"\\nNeural Network Metrics:\")\n",
        "print(\"MAE:\", nn_mae)\n",
        "print(\"MSE:\", nn_mse)\n",
        "print(\"RMSE:\", nn_rmse)\n",
        "\n",
        "# Compare with linear regression benchmark\n",
        "if nn_rmse < linear_reg_rmse:\n",
        "    print(\"\\nThe neural network model outperforms the linear regression benchmark.\")\n",
        "else:\n",
        "    print(\"\\nThe linear regression benchmark outperforms the neural network model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE_o4mByCuVQ",
        "outputId": "bb9a142a-aa96-42a1-a9ac-b99b42c45d0e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Metrics:\n",
            "MAE: 161.93889905273534\n",
            "MSE: 66590.72433896206\n",
            "RMSE: 258.051786157279\n",
            "Epoch 1/50\n",
            "38/38 [==============================] - 1s 5ms/step - loss: 185094.7344\n",
            "Epoch 2/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 181151.0469\n",
            "Epoch 3/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 167566.4688\n",
            "Epoch 4/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 139181.7969\n",
            "Epoch 5/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 101248.6875\n",
            "Epoch 6/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 72958.9844\n",
            "Epoch 7/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 63671.0938\n",
            "Epoch 8/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 61885.6641\n",
            "Epoch 9/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 60500.6328\n",
            "Epoch 10/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 59218.8242\n",
            "Epoch 11/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 58010.9062\n",
            "Epoch 12/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 56793.1836\n",
            "Epoch 13/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 55668.4414\n",
            "Epoch 14/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 54449.2031\n",
            "Epoch 15/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 53302.3438\n",
            "Epoch 16/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 52127.3750\n",
            "Epoch 17/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 50966.3867\n",
            "Epoch 18/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 49702.0273\n",
            "Epoch 19/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 48383.2695\n",
            "Epoch 20/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 47064.7891\n",
            "Epoch 21/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 45737.2305\n",
            "Epoch 22/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 44320.1172\n",
            "Epoch 23/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 42811.3516\n",
            "Epoch 24/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 41380.0977\n",
            "Epoch 25/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 39941.4766\n",
            "Epoch 26/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 38519.4648\n",
            "Epoch 27/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 37018.0742\n",
            "Epoch 28/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 35569.2500\n",
            "Epoch 29/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 34145.5742\n",
            "Epoch 30/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 32727.3086\n",
            "Epoch 31/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 31298.2754\n",
            "Epoch 32/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 29944.7246\n",
            "Epoch 33/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 28607.1699\n",
            "Epoch 34/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 27319.9297\n",
            "Epoch 35/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 25995.6816\n",
            "Epoch 36/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 24729.4512\n",
            "Epoch 37/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 23544.7227\n",
            "Epoch 38/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 22612.1562\n",
            "Epoch 39/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 21324.5469\n",
            "Epoch 40/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 20240.1172\n",
            "Epoch 41/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 19226.9258\n",
            "Epoch 42/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 18240.9180\n",
            "Epoch 43/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 17330.6309\n",
            "Epoch 44/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 16455.4863\n",
            "Epoch 45/50\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 15681.1328\n",
            "Epoch 46/50\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 14957.3398\n",
            "Epoch 47/50\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 14073.9521\n",
            "Epoch 48/50\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 13404.6318\n",
            "Epoch 49/50\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 12738.8896\n",
            "Epoch 50/50\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 12154.1387\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "\n",
            "Neural Network Metrics:\n",
            "MAE: 170.88877932442807\n",
            "MSE: 64432.83236388112\n",
            "RMSE: 253.83623138527943\n",
            "\n",
            "The neural network model outperforms the linear regression benchmark.\n"
          ]
        }
      ]
    }
  ]
}
